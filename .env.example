# ============================================
# Advanced RAG - Environment Configuration
# ============================================
# Copy this file to .env and update values as needed.
# For production, use actual secrets and secure key management.
# 
# NOTE: All settings use double underscore (__) as delimiter
# Format: <PREFIX>__<SETTING>=<VALUE>

# ============================================
# Application Configuration
# ============================================
APP__NAME=Advanced RAG API
APP__VERSION=1.0.0
APP__DEBUG=false
APP__LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ============================================
# Server Configuration
# ============================================
SERVER__HOST=0.0.0.0
SERVER__PORT=8000

# ============================================
# Ingestion Configuration
# ============================================
INGESTION__DIR=./data

# ============================================
# Chunking Configuration
# ============================================
CHUNKING__CHUNK_SIZE=200  # Characters per chunk
CHUNKING__CHUNK_OVERLAP=50  # Characters overlap between chunks
CHUNKING__STRATEGY=heading_aware  # fixed, heading_aware

# ============================================
# Embedding Configuration
# ============================================
EMBED__PROVIDER=hash  # hash, e5, bge, huggingface, openai, cohere
EMBED__MODEL=simple-hash  # Model name depends on provider
EMBED__DIM=64  # Embedding dimension (only for hash provider)
EMBED__DEVICE=cpu  # cpu, cuda, mps (for local models)
EMBED__BATCH_SIZE=32
EMBED__NORMALIZE=true
# EMBED__API_KEY=  # Required for OpenAI/Cohere providers

# --- Embedding Cache Settings ---
EMBED__CACHE_ENABLED=true  # Enable embedding caching
EMBED__CACHE_MAX_SIZE=10000  # Max embeddings to cache in memory
EMBED__CACHE_DIR=.cache/embeddings  # Cache directory (None to disable disk persistence)

# --- Provider-Specific Examples ---
# E5 Embeddings (local):
# EMBED__PROVIDER=e5
# EMBED__MODEL=intfloat/e5-small-v2  # or e5-small, e5-base, e5-large
# EMBED__DEVICE=cuda

# BGE Embeddings (local):
# EMBED__PROVIDER=bge
# EMBED__MODEL=BAAI/bge-small-en-v1.5  # or bge-small, bge-base, bge-large
# EMBED__DEVICE=cuda

# OpenAI Embeddings (API):
# EMBED__PROVIDER=openai
# EMBED__MODEL=text-embedding-3-small  # or text-embedding-3-large, text-embedding-ada-002
# EMBED__API_KEY=sk-proj-...

# Cohere Embeddings (API):
# EMBED__PROVIDER=cohere
# EMBED__MODEL=embed-english-v3.0  # or embed-english-light-v3.0, embed-multilingual-v3.0
# EMBED__API_KEY=...

# ============================================
# Vector Store (Qdrant) Configuration
# ============================================
QDRANT__URL=http://localhost:6333
QDRANT__API_KEY=  # Optional for Qdrant Cloud
QDRANT__COLLECTION_NAME=naive_collection
QDRANT__PREFER_GRPC=true
QDRANT__ENABLE_BM25=false  # Enable BM25 text indexing for hybrid search

# ============================================
# Generation (LLM) Configuration
# ============================================
GENERATOR__MODEL=gpt2  # HuggingFace model or OpenAI model name
GENERATOR__DEVICE=  # -1 for CPU, 0+ for GPU (HuggingFace only)
GENERATOR__MAX_LENGTH=128
GENERATOR__TEMPERATURE=1.0

# For OpenAI LLMs:
# GENERATOR__MODEL=gpt-4o-mini
# GENERATOR__API_KEY=sk-...
# GENERATOR__MAX_TOKENS=500

# ============================================
# RAG Pipeline Configuration
# ============================================
RAG__TOP_K=5  # Number of chunks to retrieve
RAG__MAX_CONTEXT_DOCS=3  # Max documents to use in context

# ============================================
# Reranker Configuration
# ============================================
RERANKER__MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKER__MAX_LENGTH=512
RERANKER__BATCH_SIZE=32
RERANKER__TIMEOUT_SECONDS=30.0
# RERANKER__DEVICE=cpu  # cpu, cuda, or None for auto-detect
RERANKER__FALLBACK_ENABLED=true
RERANKER__FALLBACK_STRATEGY=original_order  # original_order or score_descending
RERANKER__USE_FP16=true

# ============================================
# Query Understanding Configuration
# ============================================

# --- Query Rewriting Settings ---
QUERY__ENABLE_REWRITING=true  # Enable query rewriting
QUERY__EXPAND_ACRONYMS=true  # Expand acronyms (ML â†’ machine learning)
QUERY__FIX_TYPOS=true  # Fix common typos
QUERY__ADD_CONTEXT=true  # Add implicit context to queries
QUERY__MAX_REWRITES=3  # Maximum number of rewrites per query
QUERY__MIN_QUERY_LENGTH=3  # Minimum query length to process

# --- Synonym Expansion Settings ---
QUERY__ENABLE_SYNONYMS=true  # Enable synonym expansion
QUERY__MAX_SYNONYMS_PER_TERM=3  # Max synonyms to add per term
QUERY__MIN_TERM_LENGTH=3  # Minimum term length to expand
QUERY__EXPAND_ALL_TERMS=false  # If false, only expand key terms

# --- Intent Classification Settings ---
QUERY__ENABLE_INTENT_CLASSIFICATION=false  # Enable intent detection

# ============================================
# Cache Configuration
# ============================================

# --- Redis Connection (uses REDIS__ prefix) ---
REDIS__HOST=localhost
REDIS__PORT=6379
REDIS__DB=0
# REDIS__PASSWORD=  # Optional Redis password
REDIS__MAX_CONNECTIONS=10
REDIS__SOCKET_TIMEOUT=5
REDIS__DECODE_RESPONSES=true

# --- Cache Behavior (uses CACHE__ prefix) ---
CACHE__DEFAULT_TTL=3600  # Default time-to-live in seconds (1 hour)
CACHE__KEY_PREFIX=rag:  # Prefix for all cache keys
CACHE__ENABLED=true  # Enable/disable caching globally

# --- Semantic Cache Settings ---
CACHE__SEMANTIC_SIMILARITY_THRESHOLD=0.95  # Cosine similarity threshold (0.0-1.0)
CACHE__SEMANTIC_EMBEDDING_DIM=384  # Embedding dimension for semantic cache
CACHE__SEMANTIC_MAX_CANDIDATES=100  # Max candidates to check for similarity

# --- Staleness Monitoring ---
CACHE__STALENESS_CHECK_INTERVAL=300  # Check interval in seconds (5 minutes)
CACHE__STALENESS_THRESHOLD=3600  # Staleness threshold in seconds (1 hour)
CACHE__STALENESS_AUTO_INVALIDATE=false  # Auto-invalidate stale entries

# --- Performance Targets ---
CACHE__TARGET_HIT_RATE=0.6  # Target cache hit rate (60%)

# Sandboxed Code Execution Configuration
# Copy relevant settings to your .env file

# Security Level: strict, moderate, or permissive
SANDBOX__SECURITY_LEVEL=moderate

# Enable/disable audit logging
SANDBOX__ENABLE_AUDIT_LOGGING=true
SANDBOX__AUDIT_LOG_FILE=./logs/sandbox_audit.jsonl

# Resource Limits
SANDBOX__MAX_EXECUTION_TIME=5.0          # seconds
SANDBOX__MAX_CPU_TIME=4.0                # seconds
SANDBOX__MAX_MEMORY_MB=128               # megabytes
SANDBOX__MAX_STACK_SIZE_MB=8             # megabytes
SANDBOX__MAX_PROCESSES=1                 # number of processes
SANDBOX__MAX_OPEN_FILES=32               # file descriptors
SANDBOX__MAX_OUTPUT_SIZE=1048576         # bytes (1MB)
SANDBOX__MAX_VARIABLES=1000              # max variables to return

# Network Settings
SANDBOX__ALLOW_NETWORK=false
SANDBOX__ALLOWED_HOSTS=                  # Comma-separated: api.example.com,httpbin.org
SANDBOX__ALLOWED_PORTS=                  # Comma-separated: 80,443
SANDBOX__BLOCK_LOCAL_NETWORK=true

# Process Isolation
SANDBOX__MAX_WORKERS=2

# Tool-specific Settings
SANDBOX__TOOL_TIMEOUT=5
SANDBOX__TOOL_MAX_MEMORY_MB=128

# Example configurations for different environments:

# Production (strict security):
# SANDBOX__SECURITY_LEVEL=strict
# SANDBOX__MAX_EXECUTION_TIME=3.0
# SANDBOX__MAX_MEMORY_MB=64
# SANDBOX__ALLOW_NETWORK=false

# Development (balanced):
# SANDBOX__SECURITY_LEVEL=moderate
# SANDBOX__MAX_EXECUTION_TIME=10.0
# SANDBOX__MAX_MEMORY_MB=256
# SANDBOX__ALLOW_NETWORK=false

# Testing (permissive):
# SANDBOX__SECURITY_LEVEL=permissive
# SANDBOX__MAX_EXECUTION_TIME=15.0
# SANDBOX__MAX_MEMORY_MB=512
# SANDBOX__ALLOW_NETWORK=true
# SANDBOX__ALLOWED_HOSTS=httpbin.org,api.github.com

# ============================================
# Backward Compatibility (Legacy Format)
# ============================================
# The following legacy format is still supported but deprecated:
# APP_NAME, HOST, PORT, CHUNK_SIZE, EMBED_PROVIDER, etc.
# Please migrate to the new format with __ delimiter.